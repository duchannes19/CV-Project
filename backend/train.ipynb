{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "import pydicom\n",
    "from skimage import exposure\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "from skimage.transform import resize\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "import logging\n",
    "import re\n",
    "from pathlib import Path  # Import pathlib for path handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BASE_SEGMENTATION_DIR = Path(\"datasets/segmentation/PROSTATEX\")      # Directory containing segmentation masks\n",
    "BASE_IMAGES_DIR = Path(\"datasets/segmentation2/PROSTATEX\")          # Directory containing image slices\n",
    "\n",
    "SEGMENTATION_FILENAME = \"1-1.dcm\"                                         # Segmentation mask filename per patient\n",
    "IMAGE_FILENAME_PATTERN = r\".*\\.dcm$\"                                      # Pattern to match image slices\n",
    "\n",
    "IMG_HEIGHT, IMG_WIDTH = 256, 256                                          # Desired image height and width after resizing\n",
    "TARGET_DEPTH = 16                                                # Fixed number of slices per volume\n",
    "BATCH_SIZE = 2                                                           # Adjust based on GPU memory\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_image(file_path):\n",
    "    \"\"\"\n",
    "    Load a DICOM file and return the image array.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: Path to the DICOM file.\n",
    "    \n",
    "    Returns:\n",
    "    - image: 2D numpy array of the image data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dicom = pydicom.dcmread(file_path)\n",
    "        image = dicom.pixel_array.astype(np.float32)\n",
    "        # Rescale if necessary based on DICOM metadata\n",
    "        if 'RescaleSlope' in dicom and 'RescaleIntercept' in dicom:\n",
    "            slope = dicom.RescaleSlope\n",
    "            intercept = dicom.RescaleIntercept\n",
    "            image = image * slope + intercept\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading DICOM file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def denoise_image(image):\n",
    "    \"\"\"\n",
    "    Apply Non-Local Means denoising to the image.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: 2D numpy array.\n",
    "    \n",
    "    Returns:\n",
    "    - denoised_image: 2D numpy array.\n",
    "    \"\"\"\n",
    "    # Estimate the noise standard deviation from the noisy image\n",
    "    sigma_est = np.mean(estimate_sigma(image, multichannel=False))\n",
    "    denoised_image = denoise_nl_means(image, h=1.15 * sigma_est, fast_mode=True,\n",
    "                                     patch_size=5, patch_distance=3, multichannel=False)\n",
    "    return denoised_image\n",
    "\n",
    "def normalize_image(image, method='z-score'):\n",
    "    \"\"\"\n",
    "    Normalize the image using the specified method.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: 2D numpy array.\n",
    "    - method: 'z-score' or 'minmax'.\n",
    "    \n",
    "    Returns:\n",
    "    - normalized_image: 2D numpy array.\n",
    "    \"\"\"\n",
    "    if method == 'z-score':\n",
    "        mean = np.mean(image)\n",
    "        std = np.std(image)\n",
    "        normalized_image = (image - mean) / (std + 1e-8)\n",
    "    elif method == 'minmax':\n",
    "        min_val = np.min(image)\n",
    "        max_val = np.max(image)\n",
    "        normalized_image = (image - min_val) / (max_val - min_val + 1e-8)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown normalization method\")\n",
    "    return normalized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_volume(volume, target_depth, is_mask=False):\n",
    "    \"\"\"\n",
    "    Resample a 3D volume to have a fixed number of slices (depth).\n",
    "    \n",
    "    Parameters:\n",
    "    - volume: 3D numpy array with shape (depth, height, width).\n",
    "    - target_depth: Desired number of slices.\n",
    "    - is_mask: Boolean indicating if the volume is a mask (affects interpolation order).\n",
    "    \n",
    "    Returns:\n",
    "    - resampled_volume: 3D numpy array with shape (target_depth, height, width).\n",
    "    \"\"\"\n",
    "    current_depth = volume.shape[0]\n",
    "    if current_depth == target_depth:\n",
    "        return volume  # No resampling needed\n",
    "    \n",
    "    if is_mask:\n",
    "        # Use nearest-neighbor interpolation for masks\n",
    "        order = 0\n",
    "    else:\n",
    "        # Use linear interpolation for images\n",
    "        order = 1\n",
    "    \n",
    "    # Calculate the new indices\n",
    "    indices = np.linspace(0, current_depth - 1, target_depth)\n",
    "    resampled_volume = []\n",
    "    for i in range(volume.shape[1]):  # Iterate over height\n",
    "        for j in range(volume.shape[2]):  # Iterate over width\n",
    "            slice_1d = volume[:, i, j]\n",
    "            resampled_slice = np.interp(indices, np.arange(current_depth), slice_1d)\n",
    "            resampled_volume.append(resampled_slice)\n",
    "    \n",
    "    resampled_volume = np.array(resampled_volume).reshape(target_depth, volume.shape[1], volume.shape[2])\n",
    "    return resampled_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip_3d(volume, mask):\n",
    "    \"\"\"\n",
    "    Randomly flip the volume and mask along the horizontal and/or vertical axes.\n",
    "    \n",
    "    Parameters:\n",
    "    - volume: 3D numpy array with shape (depth, height, width).\n",
    "    - mask: 3D numpy array with shape (depth, height, width).\n",
    "    \n",
    "    Returns:\n",
    "    - volume_flipped: 3D numpy array.\n",
    "    - mask_flipped: 3D numpy array.\n",
    "    \"\"\"\n",
    "    # Flip along the width axis (axis=2)\n",
    "    if np.random.rand() < 0.5:\n",
    "        volume = np.flip(volume, axis=2)\n",
    "        mask = np.flip(mask, axis=2)\n",
    "    \n",
    "    # Flip along the height axis (axis=1)\n",
    "    if np.random.rand() < 0.5:\n",
    "        volume = np.flip(volume, axis=1)\n",
    "        mask = np.flip(mask, axis=1)\n",
    "    \n",
    "    return volume, mask\n",
    "\n",
    "def random_rotate_3d(volume, mask):\n",
    "    \"\"\"\n",
    "    Randomly rotate the volume and mask by 90 degrees around the depth axis.\n",
    "    \n",
    "    Parameters:\n",
    "    - volume: 3D numpy array with shape (depth, height, width).\n",
    "    - mask: 3D numpy array with shape (depth, height, width).\n",
    "    \n",
    "    Returns:\n",
    "    - volume_rotated: 3D numpy array.\n",
    "    - mask_rotated: 3D numpy array.\n",
    "    \"\"\"\n",
    "    k = np.random.choice([0, 1, 2, 3])\n",
    "    volume = np.rot90(volume, k, axes=(1, 2))\n",
    "    mask = np.rot90(mask, k, axes=(1, 2))\n",
    "    return volume, mask\n",
    "\n",
    "def random_scale_3d(volume, mask, scale_range=(0.9, 1.1)):\n",
    "    \"\"\"\n",
    "    Randomly scale the volume and mask along the depth axis.\n",
    "    \n",
    "    Parameters:\n",
    "    - volume: 3D numpy array with shape (depth, height, width).\n",
    "    - mask: 3D numpy array with shape (depth, height, width).\n",
    "    - scale_range: Tuple indicating the scaling factor range.\n",
    "    \n",
    "    Returns:\n",
    "    - volume_scaled: 3D numpy array.\n",
    "    - mask_scaled: 3D numpy array.\n",
    "    \"\"\"\n",
    "    current_depth = volume.shape[0]\n",
    "    target_depth = TARGET_DEPTH\n",
    "    if current_depth == target_depth:\n",
    "        return volume, mask  # No scaling needed\n",
    "    \n",
    "    # Resample using the resample_volume function\n",
    "    volume = resample_volume(volume, target_depth, is_mask=False)\n",
    "    mask = resample_volume(mask, target_depth, is_mask=True)\n",
    "    \n",
    "    return volume, mask\n",
    "\n",
    "def augment_data_3d(volume, mask):\n",
    "    \"\"\"\n",
    "    Apply a series of random 3D augmentations to the volume and mask.\n",
    "    \n",
    "    Parameters:\n",
    "    - volume: 3D numpy array with shape (depth, height, width).\n",
    "    - mask: 3D numpy array with shape (depth, height, width).\n",
    "    \n",
    "    Returns:\n",
    "    - volume_augmented: 3D numpy array.\n",
    "    - mask_augmented: 3D numpy array.\n",
    "    \"\"\"\n",
    "    volume, mask = random_flip_3d(volume, mask)\n",
    "    volume, mask = random_rotate_3d(volume, mask)\n",
    "    volume, mask = random_scale_3d(volume, mask)\n",
    "    return volume, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(segmentation_dir, images_dir, segmentation_filename, img_height, img_width, target_depth):\n",
    "    \"\"\"\n",
    "    Load images and masks from separate directories, preprocess them, resample to fixed depth, and return as numpy arrays.\n",
    "    \n",
    "    Parameters:\n",
    "    - segmentation_dir: Directory containing segmentation masks.\n",
    "    - images_dir: Directory containing image slices.\n",
    "    - segmentation_filename: Filename of the segmentation mask per patient.\n",
    "    - img_height: Desired image height after resizing.\n",
    "    - img_width: Desired image width after resizing.\n",
    "    - target_depth: Fixed number of slices per volume.\n",
    "    \n",
    "    Returns:\n",
    "    - images: Numpy array of preprocessed image volumes.\n",
    "    - masks: Numpy array of corresponding segmentation masks.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    # Compile regex pattern for image filenames\n",
    "    image_pattern = re.compile(IMAGE_FILENAME_PATTERN)\n",
    "    \n",
    "    # List of patients based on segmentation directory\n",
    "    patients = [p for p in segmentation_dir.iterdir() if p.is_dir()]\n",
    "\n",
    "    print(f\"Found {len(patients)} patients\")\n",
    "    \n",
    "    for patient_dir in patients:\n",
    "        patient = patient_dir.name\n",
    "        mask_path = patient_dir / segmentation_filename\n",
    "        if not mask_path.exists():\n",
    "            print(f\"Segmentation mask not found for patient: {patient}\")\n",
    "            continue\n",
    "        \n",
    "        # Load segmentation mask\n",
    "        mask_volume = load_dicom_image(mask_path)\n",
    "        if mask_volume is None:\n",
    "            print(f\"Failed to load mask for patient: {patient}\")\n",
    "            continue\n",
    "        \n",
    "        # Check if mask_volume is 3D; if not, expand dimensions\n",
    "        if len(mask_volume.shape) == 2:\n",
    "            mask_volume = np.expand_dims(mask_volume, axis=0)  # Shape: (depth=1, height, width)\n",
    "        \n",
    "        # Path to image slices\n",
    "        patient_img_dir = images_dir / patient\n",
    "        if not patient_img_dir.exists():\n",
    "            print(f\"Image directory not found for patient: {patient}\")\n",
    "            continue\n",
    "        \n",
    "        # List all DICOM files in image directory matching the pattern\n",
    "        img_files = sorted([f for f in patient_img_dir.iterdir() if f.is_file() and image_pattern.match(f.name)])\n",
    "        if len(img_files) == 0:\n",
    "            print(f\"No image slices found for patient: {patient}\")\n",
    "            continue\n",
    "        \n",
    "        # Load each slice\n",
    "        img_slices = []\n",
    "        for img_file in img_files:\n",
    "            img_slice = load_dicom_image(img_file)\n",
    "            if img_slice is None:\n",
    "                print(f\"Failed to load image slice: {img_file}\")\n",
    "                break\n",
    "            img_slices.append(img_slice)\n",
    "        \n",
    "        if len(img_slices) == 0:\n",
    "            print(f\"No valid image slices loaded for patient: {patient}\")\n",
    "            continue\n",
    "        \n",
    "        # Stack slices to form a 3D volume\n",
    "        img_volume = np.stack(img_slices, axis=0)  # Shape: (depth, height, width)\n",
    "        \n",
    "        # Resample image and mask to fixed depth\n",
    "        img_volume, mask_volume = augment_data_3d(img_volume, mask_volume)\n",
    "        \n",
    "        # Preprocessing: Denoising and Normalization\n",
    "        # Already applied in augment_data_3d function\n",
    "        \n",
    "        # Resize each slice to desired dimensions\n",
    "        img_volume_resized = []\n",
    "        mask_volume_resized = []\n",
    "        for slice_img, slice_mask in zip(img_volume, mask_volume):\n",
    "            slice_img = cv2.resize(slice_img, (img_width, img_height), interpolation=cv2.INTER_LINEAR)\n",
    "            slice_mask = cv2.resize(slice_mask, (img_width, img_height), interpolation=cv2.INTER_NEAREST)\n",
    "            img_volume_resized.append(slice_img)\n",
    "            mask_volume_resized.append(slice_mask)\n",
    "        \n",
    "        img_volume_resized = np.array(img_volume_resized)\n",
    "        mask_volume_resized = np.array(mask_volume_resized)\n",
    "        \n",
    "        # Ensure masks are binary\n",
    "        mask_volume_resized = (mask_volume_resized > 0.5).astype(np.uint8)\n",
    "        \n",
    "        images.append(img_volume_resized)\n",
    "        masks.append(mask_volume_resized)\n",
    "\n",
    "        print(f\"Processed patient: {patient}\")\n",
    "    \n",
    "    images = np.array(images)  # Shape: (num_patients, depth, height, width)\n",
    "    masks = np.array(masks)    # Shape: (num_patients, depth, height, width)\n",
    "    \n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66 patients\n",
      "Processed patient: ProstateX-0004\n",
      "Processed patient: ProstateX-0007\n",
      "Processed patient: ProstateX-0009\n",
      "Processed patient: ProstateX-0015\n",
      "Processed patient: ProstateX-0020\n",
      "Processed patient: ProstateX-0026\n",
      "Processed patient: ProstateX-0046\n",
      "Processed patient: ProstateX-0054\n",
      "Processed patient: ProstateX-0056\n",
      "Processed patient: ProstateX-0065\n",
      "Processed patient: ProstateX-0066\n",
      "Processed patient: ProstateX-0069\n",
      "Processed patient: ProstateX-0070\n",
      "Processed patient: ProstateX-0072\n",
      "Processed patient: ProstateX-0076\n",
      "Processed patient: ProstateX-0083\n",
      "Processed patient: ProstateX-0084\n",
      "Processed patient: ProstateX-0089\n",
      "Processed patient: ProstateX-0090\n",
      "Processed patient: ProstateX-0094\n",
      "Processed patient: ProstateX-0096\n",
      "Processed patient: ProstateX-0102\n",
      "Processed patient: ProstateX-0111\n",
      "Processed patient: ProstateX-0112\n",
      "Processed patient: ProstateX-0117\n",
      "Processed patient: ProstateX-0118\n",
      "Processed patient: ProstateX-0121\n",
      "Processed patient: ProstateX-0125\n",
      "Processed patient: ProstateX-0129\n",
      "Processed patient: ProstateX-0130\n",
      "Processed patient: ProstateX-0134\n",
      "Processed patient: ProstateX-0136\n",
      "Processed patient: ProstateX-0141\n",
      "Processed patient: ProstateX-0142\n",
      "Processed patient: ProstateX-0144\n",
      "Processed patient: ProstateX-0150\n",
      "Processed patient: ProstateX-0156\n",
      "Processed patient: ProstateX-0161\n",
      "Processed patient: ProstateX-0168\n",
      "Processed patient: ProstateX-0170\n",
      "Processed patient: ProstateX-0176\n",
      "Processed patient: ProstateX-0177\n",
      "Processed patient: ProstateX-0182\n",
      "Processed patient: ProstateX-0183\n",
      "Processed patient: ProstateX-0184\n",
      "Processed patient: ProstateX-0188\n",
      "Processed patient: ProstateX-0193\n",
      "Processed patient: ProstateX-0196\n",
      "Processed patient: ProstateX-0198\n",
      "Processed patient: ProstateX-0201\n",
      "Processed patient: ProstateX-0209\n",
      "Processed patient: ProstateX-0217\n",
      "Processed patient: ProstateX-0219\n",
      "Processed patient: ProstateX-0234\n",
      "Processed patient: ProstateX-0241\n",
      "Processed patient: ProstateX-0244\n",
      "Processed patient: ProstateX-0249\n",
      "Processed patient: ProstateX-0254\n",
      "Processed patient: ProstateX-0265\n",
      "Processed patient: ProstateX-0275\n",
      "Processed patient: ProstateX-0297\n",
      "Processed patient: ProstateX-0309\n",
      "Processed patient: ProstateX-0311\n",
      "Processed patient: ProstateX-0323\n",
      "Processed patient: ProstateX-0334\n",
      "Processed patient: ProstateX-0340\n",
      "Loaded 66 patients.\n",
      "Image shape: (66, 16, 256, 256)\n",
      "Mask shape: (66, 16, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "images, masks = load_dataset(\n",
    "    segmentation_dir=BASE_SEGMENTATION_DIR,\n",
    "    images_dir=BASE_IMAGES_DIR,\n",
    "    segmentation_filename=SEGMENTATION_FILENAME,\n",
    "    img_height=IMG_HEIGHT,\n",
    "    img_width=IMG_WIDTH,\n",
    "    target_depth=TARGET_DEPTH\n",
    ")\n",
    "\n",
    "print(f\"Loaded {images.shape[0]} patients.\")\n",
    "print(f\"Image shape: {images.shape}\")  # Expected: (num_patients, depth=19, height=256, width=256)\n",
    "print(f\"Mask shape: {masks.shape}\")    # Expected: (num_patients, depth=19, height=256, width=256)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (52, 16, 256, 256), (52, 16, 256, 256)\n",
      "Validation set: (14, 16, 256, 256), (14, 16, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    images, masks, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_3d(X, Y, batch_size, img_height, img_width, target_depth):\n",
    "    \"\"\"\n",
    "    Generate batches of augmented 3D data.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Numpy array of image volumes (num_patients, depth, height, width).\n",
    "    - Y: Numpy array of mask volumes (num_patients, depth, height, width).\n",
    "    - batch_size: Number of samples per batch.\n",
    "    - img_height: Image height.\n",
    "    - img_width: Image width.\n",
    "    - target_depth: Fixed number of slices per volume.\n",
    "    \n",
    "    Yields:\n",
    "    - Batch of images and masks with shape (batch_size, depth, height, width, 1).\n",
    "    \"\"\"\n",
    "    num_samples = X.shape[0]\n",
    "    while True:\n",
    "        idxs = np.random.permutation(num_samples)\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_idxs = idxs[i:i + batch_size]\n",
    "            batch_imgs = []\n",
    "            batch_masks = []\n",
    "            for idx in batch_idxs:\n",
    "                img, mask = X[idx], Y[idx]\n",
    "                img, mask = augment_data_3d(img, mask)\n",
    "                img = np.expand_dims(img, axis=-1)  # Shape: (depth, height, width, 1)\n",
    "                mask = np.expand_dims(mask, axis=-1)  # Shape: (depth, height, width, 1)\n",
    "                batch_imgs.append(img)\n",
    "                batch_masks.append(mask)\n",
    "            yield np.array(batch_imgs), np.array(batch_masks)\n",
    "\n",
    "# Create generators\n",
    "train_gen = data_generator_3d(\n",
    "    X_train, y_train, BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH, TARGET_DEPTH\n",
    ")\n",
    "val_gen = data_generator_3d(\n",
    "    X_val, y_val, BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH, TARGET_DEPTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 16, 256, 25  0           []                               \n",
      "                                6, 1)]                                                            \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)                (None, 16, 256, 256  896         ['input_1[0][0]']                \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)              (None, 16, 256, 256  27680       ['conv3d[0][0]']                 \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3D)   (None, 8, 128, 128,  0           ['conv3d_1[0][0]']               \n",
      "                                 32)                                                              \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)              (None, 8, 128, 128,  55360       ['max_pooling3d[0][0]']          \n",
      "                                 64)                                                              \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)              (None, 8, 128, 128,  110656      ['conv3d_2[0][0]']               \n",
      "                                 64)                                                              \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPooling3D)  (None, 4, 64, 64, 6  0          ['conv3d_3[0][0]']               \n",
      "                                4)                                                                \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)              (None, 4, 64, 64, 1  221312      ['max_pooling3d_1[0][0]']        \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)              (None, 4, 64, 64, 1  442496      ['conv3d_4[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_2 (MaxPooling3D)  (None, 2, 32, 32, 1  0          ['conv3d_5[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)              (None, 2, 32, 32, 2  884992      ['max_pooling3d_2[0][0]']        \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " conv3d_7 (Conv3D)              (None, 2, 32, 32, 2  1769728     ['conv3d_6[0][0]']               \n",
      "                                56)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose (Conv3DTransp  (None, 4, 64, 64, 1  262272     ['conv3d_7[0][0]']               \n",
      " ose)                           28)                                                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4, 64, 64, 2  0           ['conv3d_transpose[0][0]',       \n",
      "                                56)                               'conv3d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_8 (Conv3D)              (None, 4, 64, 64, 1  884864      ['concatenate[0][0]']            \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_9 (Conv3D)              (None, 4, 64, 64, 1  442496      ['conv3d_8[0][0]']               \n",
      "                                28)                                                               \n",
      "                                                                                                  \n",
      " conv3d_transpose_1 (Conv3DTran  (None, 8, 128, 128,  65600      ['conv3d_9[0][0]']               \n",
      " spose)                          64)                                                              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 128, 128,  0           ['conv3d_transpose_1[0][0]',     \n",
      "                                 128)                             'conv3d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_10 (Conv3D)             (None, 8, 128, 128,  221248      ['concatenate_1[0][0]']          \n",
      "                                 64)                                                              \n",
      "                                                                                                  \n",
      " conv3d_11 (Conv3D)             (None, 8, 128, 128,  110656      ['conv3d_10[0][0]']              \n",
      "                                 64)                                                              \n",
      "                                                                                                  \n",
      " conv3d_transpose_2 (Conv3DTran  (None, 16, 256, 256  16416      ['conv3d_11[0][0]']              \n",
      " spose)                         , 32)                                                             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 16, 256, 256  0           ['conv3d_transpose_2[0][0]',     \n",
      "                                , 64)                             'conv3d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_12 (Conv3D)             (None, 16, 256, 256  55328       ['concatenate_2[0][0]']          \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_13 (Conv3D)             (None, 16, 256, 256  27680       ['conv3d_12[0][0]']              \n",
      "                                , 32)                                                             \n",
      "                                                                                                  \n",
      " conv3d_14 (Conv3D)             (None, 16, 256, 256  33          ['conv3d_13[0][0]']              \n",
      "                                , 1)                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,599,713\n",
      "Trainable params: 5,599,713\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_3d_unet(input_shape=(TARGET_DEPTH, IMG_HEIGHT, IMG_WIDTH, 1)):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling3D((2, 2, 2))(c1)\n",
    "    \n",
    "    c2 = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling3D((2, 2, 2))(c2)\n",
    "    \n",
    "    c3 = layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling3D((2, 2, 2))(c3)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c4 = layers.Conv3D(256, (3, 3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv3D(256, (3, 3, 3), activation='relu', padding='same')(c4)\n",
    "    \n",
    "    # Decoder\n",
    "    u5 = layers.Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(c4)\n",
    "    u5 = layers.concatenate([u5, c3])\n",
    "    c5 = layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same')(u5)\n",
    "    c5 = layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same')(c5)\n",
    "    \n",
    "    u6 = layers.Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(c5)\n",
    "    u6 = layers.concatenate([u6, c2])\n",
    "    c6 = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(c6)\n",
    "    \n",
    "    u7 = layers.Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(c6)\n",
    "    u7 = layers.concatenate([u7, c1])\n",
    "    c7 = layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same')(c7)\n",
    "    \n",
    "    outputs = layers.Conv3D(1, (1, 1, 1), activation='sigmoid')(c7)\n",
    "    \n",
    "    model = keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_3d_unet()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (52, 16, 256, 256), (52, 16, 256, 256)\n",
      "Validation set: (14, 16, 256, 256), (14, 16, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    images, masks, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.5004 - accuracy: 0.9500\n",
      "Epoch 1: val_loss improved from inf to 0.11531, saving model to prostate_segmentation_best.keras\n",
      "26/26 [==============================] - 186s 3s/step - loss: 0.5004 - accuracy: 0.9500 - val_loss: 0.1153 - val_accuracy: 0.9751\n",
      "Epoch 2/50\n",
      " 6/26 [=====>........................] - ETA: 58s - loss: 0.1077 - accuracy: 0.9776 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 22\u001b[0m\n\u001b[0;32m      6\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      7\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprostate_segmentation_best.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     )\n\u001b[0;32m     19\u001b[0m ]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\andri\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Calculate steps per epoch\n",
    "steps_per_epoch = len(X_train) // BATCH_SIZE\n",
    "validation_steps = len(X_val) // BATCH_SIZE\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"prostate_segmentation_best.keras\", \n",
    "        save_best_only=True, \n",
    "        monitor='val_loss',\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=10, \n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient_np(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Dice Similarity Coefficient.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: Ground truth mask (3D numpy array).\n",
    "    - y_pred: Predicted mask (3D numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - Dice coefficient.\n",
    "    \"\"\"\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (np.sum(y_true_f) + np.sum(y_pred_f) + 1e-8)\n",
    "\n",
    "def hausdorff_distance_np(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Hausdorff Distance between two binary masks.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: Ground truth mask (3D numpy array).\n",
    "    - y_pred: Predicted mask (3D numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - Hausdorff distance.\n",
    "    \"\"\"\n",
    "    y_true_pts = np.argwhere(y_true)\n",
    "    y_pred_pts = np.argwhere(y_pred)\n",
    "    \n",
    "    if len(y_true_pts) == 0 or len(y_pred_pts) == 0:\n",
    "        return np.inf\n",
    "    \n",
    "    forward_hd = directed_hausdorff(y_true_pts, y_pred_pts)[0]\n",
    "    backward_hd = directed_hausdorff(y_pred_pts, y_true_pts)[0]\n",
    "    \n",
    "    return max(forward_hd, backward_hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model.load_weights(\"prostate_segmentation_best.keras\")\n",
    "\n",
    "# Predict on the validation set\n",
    "val_predictions = model.predict(X_val)\n",
    "\n",
    "# Binarize predictions\n",
    "val_predictions_bin = (val_predictions > 0.5).astype(np.uint8)\n",
    "\n",
    "# Compute metrics\n",
    "dice_scores = []\n",
    "hausdorff_scores = []\n",
    "\n",
    "for i in range(len(y_val)):\n",
    "    dice = dice_coefficient_np(y_val[i], val_predictions_bin[i, :, :, :, 0])\n",
    "    hd = hausdorff_distance_np(y_val[i], val_predictions_bin[i, :, :, :, 0])\n",
    "    dice_scores.append(dice)\n",
    "    hausdorff_scores.append(hd)\n",
    "\n",
    "print(f\"Mean Dice Coefficient on Validation Set: {np.mean(dice_scores):.4f}\")\n",
    "print(f\"Mean Hausdorff Distance on Validation Set: {np.mean(hausdorff_scores):.4f} mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"prostate_segmentation.keras\")\n",
    "print(\"Model saved as prostate_segmentation.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss and accuracy values\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss', color='orange')\n",
    "plt.title('Model Loss Over Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', color='green')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy', color='red')\n",
    "plt.title('Model Accuracy Over Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
