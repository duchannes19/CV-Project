{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing some dependencies...\")\n",
    "%pip install gdown\n",
    "%pip install SimpleITK\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "import pydicom\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "import re\n",
    "from pathlib import Path  # Import pathlib for path handling\n",
    "import gdown\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://drive.google.com/file/d/17fKi5QYROdVoUjmzC90TCe_Tal9hNPph/view?usp=sharing\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset.zip\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mgdown\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuzzy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Unzip the dataset\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnzipping the dataset...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\site-packages\\gdown\\download.py:202\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[0;32m    199\u001b[0m     is_gdrive_download_link \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (gdrive_file_id \u001b[38;5;129;01mand\u001b[39;00m is_gdrive_download_link):\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\site-packages\\requests\\sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \n\u001b[0;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\site-packages\\requests\\sessions.py:724\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[0;32m    723\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 724\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    726\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\site-packages\\requests\\sessions.py:724\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[0;32m    723\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 724\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    726\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\site-packages\\requests\\sessions.py:265\u001b[0m, in \u001b[0;36mSessionRedirectMixin.resolve_redirects\u001b[1;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m req\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 265\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    266\u001b[0m         req,\n\u001b[0;32m    267\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    268\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    269\u001b[0m         verify\u001b[38;5;241m=\u001b[39mverify,\n\u001b[0;32m    270\u001b[0m         cert\u001b[38;5;241m=\u001b[39mcert,\n\u001b[0;32m    271\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    272\u001b[0m         allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39madapter_kwargs,\n\u001b[0;32m    274\u001b[0m     )\n\u001b[0;32m    276\u001b[0m     extract_cookies_to_jar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcookies, prepared_request, resp\u001b[38;5;241m.\u001b[39mraw)\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\socket.py:716\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\envs\\tf\\lib\\ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main_path = Path.cwd()  # Get the current working directory\n",
    "\n",
    "if not os.path.exists(main_path / 'datasets'):\n",
    "    \n",
    "    # Download the dataset (zip)\n",
    "\n",
    "    url = 'https://drive.google.com/file/d/17fKi5QYROdVoUjmzC90TCe_Tal9hNPph/view?usp=sharing'\n",
    "\n",
    "    output = 'dataset.zip'\n",
    "\n",
    "    gdown.download(url, output, quiet=False, fuzzy=True)\n",
    "\n",
    "    # Unzip the dataset\n",
    "\n",
    "    print('Unzipping the dataset...')\n",
    "    with zipfile.ZipFile(output, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "\n",
    "    print('Dataset unzipped successfully!')\n",
    "else:\n",
    "    print('Dataset already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BASE_SEGMENTATION_DIR = Path(\"datasets/segmentation/PROSTATEx\")      # Directory containing segmentation masks\n",
    "BASE_IMAGES_DIR = Path(\"datasets/segmentation2/PROSTATEx\")          # Directory containing image slices\n",
    "\n",
    "SEGMENTATION_FILENAME = \"1-1.dcm\"                                         # Segmentation mask filename per patient\n",
    "IMAGE_FILENAME_PATTERN = r\".*\\.dcm$\"                                      # Pattern to match image slices\n",
    "\n",
    "IMG_HEIGHT, IMG_WIDTH = 256, 256                                          # Desired image height and width after resizing\n",
    "TARGET_DEPTH = 16                                                # Fixed number of slices per volume\n",
    "BATCH_SIZE = 2                                                           # Adjust based on GPU memory\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pad_or_crop_volume(volume, target_depth):\n",
    "    current_depth = volume.shape[0]\n",
    "    if current_depth == target_depth:\n",
    "        return volume\n",
    "    elif current_depth > target_depth:\n",
    "        # Crop center\n",
    "        start = (current_depth - target_depth) // 2\n",
    "        end = start + target_depth\n",
    "        return volume[start:end]\n",
    "    else:\n",
    "        # Pad with zeros at both ends if needed\n",
    "        diff = target_depth - current_depth\n",
    "        pad_before = diff // 2\n",
    "        pad_after = diff - pad_before\n",
    "        padding = ((pad_before, pad_after), (0,0), (0,0))\n",
    "        return np.pad(volume, padding, mode='constant', constant_values=0)\n",
    "\n",
    "def load_sitk_volume_from_directory(directory, filename_pattern=None):\n",
    "    \"\"\"\n",
    "    Load a DICOM series from a directory using SimpleITK and return as a NumPy array.\n",
    "    If filename_pattern is given, filter the files. Otherwise, load all DICOM files in the directory.\n",
    "    \n",
    "    Returns None if no valid DICOM series found.\n",
    "    \"\"\"\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    if filename_pattern:\n",
    "        # Filter files according to pattern\n",
    "        all_files = [os.path.join(directory, f) for f in os.listdir(directory)]\n",
    "        filtered_files = [f for f in all_files if re.match(filename_pattern, os.path.basename(f))]\n",
    "        if len(filtered_files) == 0:\n",
    "            return None\n",
    "        reader.SetFileNames(filtered_files)\n",
    "    else:\n",
    "        # Use GetGDCMSeriesFileNames to automatically find the series\n",
    "        dicom_files = reader.GetGDCMSeriesFileNames(directory)\n",
    "        if len(dicom_files) == 0:\n",
    "            return None\n",
    "        reader.SetFileNames(dicom_files)\n",
    "    \n",
    "    image = reader.Execute()\n",
    "    image_array = sitk.GetArrayFromImage(image)  # shape: (depth, height, width)\n",
    "    return image_array\n",
    "\n",
    "def load_sitk_image(filepath):\n",
    "    \"\"\"\n",
    "    Load a single DICOM file or other image file directly with SimpleITK and return as numpy array.\n",
    "    This is for masks that are a single DICOM (not a series).\n",
    "    If the mask is multi-slice, it might still load as a volume.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        return None\n",
    "    image = sitk.ReadImage(str(filepath))\n",
    "    image_array = sitk.GetArrayFromImage(image)  # (depth, height, width) or (height, width) if single slice\n",
    "    return image_array\n",
    "\n",
    "def load_dataset(segmentation_dir, images_dir, segmentation_filename, img_height, img_width, target_depth):\n",
    "    \"\"\"\n",
    "    Load images and masks from separate directories using SimpleITK,\n",
    "    preprocess them, pad/crop to a fixed depth, and return as numpy arrays.\n",
    "    \n",
    "    Parameters:\n",
    "    - segmentation_dir: Directory containing segmentation masks (one per patient).\n",
    "    - images_dir: Directory containing image slices in DICOM format (multiple per patient).\n",
    "    - segmentation_filename: Filename of the segmentation mask per patient.\n",
    "    - img_height: Desired image height after resizing.\n",
    "    - img_width: Desired image width after resizing.\n",
    "    - target_depth: Fixed number of slices per volume.\n",
    "    \n",
    "    Returns:\n",
    "    - images: Numpy array (num_patients, target_depth, img_height, img_width)\n",
    "    - masks: Numpy array (num_patients, target_depth, img_height, img_width)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    IMAGE_FILENAME_PATTERN = r\".*\\.dcm$\"  # example: load only files ending with .dcm\n",
    "    \n",
    "    # List of patients based on segmentation directory\n",
    "    patients = [p for p in segmentation_dir.iterdir() if p.is_dir()]\n",
    "\n",
    "    print(f\"Found {len(patients)} patients\")\n",
    "    \n",
    "    for patient_dir in patients:\n",
    "        patient = patient_dir.name\n",
    "        mask_path = patient_dir / segmentation_filename\n",
    "        if not mask_path.exists():\n",
    "            print(f\"Segmentation mask not found for patient: {patient}\")\n",
    "            continue\n",
    "        \n",
    "        # Load segmentation mask using SimpleITK\n",
    "        mask_volume = load_sitk_image(mask_path)\n",
    "        if mask_volume is None:\n",
    "            print(f\"Failed to load mask for patient: {patient}\")\n",
    "            continue\n",
    "        \n",
    "        # Ensure mask_volume is 3D\n",
    "        if mask_volume.ndim == 2:\n",
    "            mask_volume = np.expand_dims(mask_volume, axis=0)  # (1, H, W)\n",
    "        \n",
    "        # Path to image directory\n",
    "        patient_img_dir = os.path.join(images_dir, patient)\n",
    "        if not os.path.exists(patient_img_dir):\n",
    "            print(f\"Image directory not found for patient: {patient}\")\n",
    "            continue\n",
    "        \n",
    "        # Load image volume\n",
    "        img_volume = load_sitk_volume_from_directory(patient_img_dir, IMAGE_FILENAME_PATTERN)\n",
    "        if img_volume is None or len(img_volume) == 0:\n",
    "            print(f\"No image slices found for patient: {patient}\")\n",
    "            continue\n",
    "        \n",
    "        # Pad or crop volumes to target_depth\n",
    "        img_volume = pad_or_crop_volume(img_volume, target_depth)\n",
    "        mask_volume = pad_or_crop_volume(mask_volume, target_depth)\n",
    "        \n",
    "        # Resize each slice to desired dimensions\n",
    "        img_volume_resized = []\n",
    "        mask_volume_resized = []\n",
    "        depth = img_volume.shape[0]\n",
    "        for i in range(depth):\n",
    "            slice_img = img_volume[i]\n",
    "            slice_mask = mask_volume[i]\n",
    "            \n",
    "            # Resize image and mask\n",
    "            slice_img = cv2.resize(slice_img, (img_width, img_height), interpolation=cv2.INTER_LINEAR)\n",
    "            slice_mask = cv2.resize(slice_mask, (img_width, img_height), interpolation=cv2.INTER_NEAREST)\n",
    "            \n",
    "            img_volume_resized.append(slice_img)\n",
    "            mask_volume_resized.append(slice_mask)\n",
    "        \n",
    "        img_volume_resized = np.array(img_volume_resized)\n",
    "        mask_volume_resized = np.array(mask_volume_resized)\n",
    "        \n",
    "        # Ensure masks are binary\n",
    "        mask_volume_resized = (mask_volume_resized > 0.5).astype(np.uint8)\n",
    "        \n",
    "        images.append(img_volume_resized)\n",
    "        masks.append(mask_volume_resized)\n",
    "        \n",
    "        print(f\"Processed patient: {patient}\")\n",
    "    \n",
    "    images = np.array(images)  # (num_patients, target_depth, img_height, img_width)\n",
    "    masks = np.array(masks)    # (num_patients, target_depth, img_height, img_width)\n",
    "    \n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "images, masks = load_dataset(\n",
    "    segmentation_dir=BASE_SEGMENTATION_DIR,\n",
    "    images_dir=BASE_IMAGES_DIR,\n",
    "    segmentation_filename=SEGMENTATION_FILENAME,\n",
    "    img_height=IMG_HEIGHT,\n",
    "    img_width=IMG_WIDTH,\n",
    "    target_depth=TARGET_DEPTH\n",
    ")\n",
    "\n",
    "print(f\"Loaded {images.shape[0]} patients.\")\n",
    "print(f\"Image shape: {images.shape}\")  # Expected: (num_patients, depth=19, height=256, width=256)\n",
    "print(f\"Mask shape: {masks.shape}\")    # Expected: (num_patients, depth=19, height=256, width=256)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    images, masks, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_flip_3d(volume, mask):\n",
    "    \"\"\"\n",
    "    Randomly flip the volume and mask along the horizontal and/or vertical axes.\n",
    "    \n",
    "    Parameters:\n",
    "    - volume: 3D numpy array with shape (depth, height, width).\n",
    "    - mask: 3D numpy array with shape (depth, height, width).\n",
    "    \n",
    "    Returns:\n",
    "    - volume_flipped: 3D numpy array.\n",
    "    - mask_flipped: 3D numpy array.\n",
    "    \"\"\"\n",
    "    # Flip along the width axis (axis=2)\n",
    "    if np.random.rand() < 0.5:\n",
    "        volume = np.flip(volume, axis=2)\n",
    "        mask = np.flip(mask, axis=2)\n",
    "    \n",
    "    # Flip along the height axis (axis=1)\n",
    "    if np.random.rand() < 0.5:\n",
    "        volume = np.flip(volume, axis=1)\n",
    "        mask = np.flip(mask, axis=1)\n",
    "    \n",
    "    return volume, mask\n",
    "\n",
    "def random_rotate_3d(volume, mask):\n",
    "    \"\"\"\n",
    "    Randomly rotate the volume and mask by 90 degrees around the depth axis.\n",
    "    \n",
    "    Parameters:\n",
    "    - volume: 3D numpy array with shape (depth, height, width).\n",
    "    - mask: 3D numpy array with shape (depth, height, width).\n",
    "    \n",
    "    Returns:\n",
    "    - volume_rotated: 3D numpy array.\n",
    "    - mask_rotated: 3D numpy array.\n",
    "    \"\"\"\n",
    "    k = np.random.choice([0, 1, 2, 3])\n",
    "    volume = np.rot90(volume, k, axes=(1, 2))\n",
    "    mask = np.rot90(mask, k, axes=(1, 2))\n",
    "    return volume, mask\n",
    "\n",
    "def augment_data_3d(volume, mask):\n",
    "    \"\"\"\n",
    "    Apply a series of random 3D augmentations to the volume and mask.\n",
    "    \n",
    "    Parameters:\n",
    "    - volume: 3D numpy array with shape (depth, height, width).\n",
    "    - mask: 3D numpy array with shape (depth, height, width).\n",
    "    \n",
    "    Returns:\n",
    "    - volume_augmented: 3D numpy array.\n",
    "    - mask_augmented: 3D numpy array.\n",
    "    \"\"\"\n",
    "    volume, mask = random_flip_3d(volume, mask)\n",
    "    volume, mask = random_rotate_3d(volume, mask)\n",
    "    # No scaling or resampling is performed now\n",
    "    return volume, mask\n",
    "\n",
    "def data_generator_3d(X, Y, batch_size, img_height, img_width):\n",
    "    \"\"\"\n",
    "    Generate batches of augmented 3D data.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Numpy array of image volumes (num_patients, depth, height, width).\n",
    "    - Y: Numpy array of mask volumes (num_patients, depth, height, width).\n",
    "    - batch_size: Number of samples per batch.\n",
    "    - img_height: Image height (if needed for resizing outside this function).\n",
    "    - img_width: Image width (if needed for resizing outside this function).\n",
    "    \n",
    "    Yields:\n",
    "    - A tuple (batch_imgs, batch_masks) where:\n",
    "      batch_imgs: (batch_size, depth, height, width, 1)\n",
    "      batch_masks: (batch_size, depth, height, width, 1)\n",
    "    \"\"\"\n",
    "    num_samples = X.shape[0]\n",
    "    while True:\n",
    "        idxs = np.random.permutation(num_samples)\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_idxs = idxs[i:i + batch_size]\n",
    "            batch_imgs = []\n",
    "            batch_masks = []\n",
    "            for idx in batch_idxs:\n",
    "                img, mask = X[idx], Y[idx]\n",
    "                img, mask = augment_data_3d(img, mask)\n",
    "                img = np.expand_dims(img, axis=-1)   # Shape: (depth, height, width, 1)\n",
    "                mask = np.expand_dims(mask, axis=-1) # Shape: (depth, height, width, 1)\n",
    "                batch_imgs.append(img)\n",
    "                batch_masks.append(mask)\n",
    "            yield np.array(batch_imgs), np.array(batch_masks)\n",
    "\n",
    "# Example usage:\n",
    "train_gen = data_generator_3d(X_train, y_train, BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH)\n",
    "val_gen = data_generator_3d(X_val, y_val, BATCH_SIZE, IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "# Visualize a few augmented samples\n",
    "augmented_samples = next(train_gen)\n",
    "augmented_images, augmented_masks = augmented_samples\n",
    "\n",
    "# Get the actual batch size\n",
    "batch_size = augmented_images.shape[0]\n",
    "num_samples_to_show = min(4, batch_size)  # Show up to 4 samples, or less if batch is smaller\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(num_samples_to_show):\n",
    "    plt.subplot(num_samples_to_show, 2, 2*i+1)\n",
    "    plt.imshow(augmented_images[i][0, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Augmented Image\")\n",
    "    \n",
    "    plt.subplot(num_samples_to_show, 2, 2*i+2)\n",
    "    plt.imshow(augmented_masks[i][0, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Augmented Mask\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Optimizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def conv_block_3d(x, filters):\n",
    "    x = layers.Conv3D(filters, (3, 3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv3D(filters, (3, 3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def build_3d_unet(input_shape=(TARGET_DEPTH, IMG_HEIGHT, IMG_WIDTH, 1)):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = conv_block_3d(inputs, 32)\n",
    "    p1 = layers.MaxPooling3D((2, 2, 2))(c1)\n",
    "    \n",
    "    c2 = conv_block_3d(p1, 64)\n",
    "    p2 = layers.MaxPooling3D((2, 2, 2))(c2)\n",
    "    \n",
    "    c3 = conv_block_3d(p2, 128)\n",
    "    p3 = layers.MaxPooling3D((2, 2, 2))(c3)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c4 = conv_block_3d(p3, 256)\n",
    "    \n",
    "    # Decoder\n",
    "    u5 = layers.Conv3DTranspose(128, (2,2,2), strides=(2,2,2), padding='same')(c4)\n",
    "    u5 = layers.concatenate([u5, c3])\n",
    "    c5 = conv_block_3d(u5, 128)\n",
    "    \n",
    "    u6 = layers.Conv3DTranspose(64, (2,2,2), strides=(2,2,2), padding='same')(c5)\n",
    "    u6 = layers.concatenate([u6, c2])\n",
    "    c6 = conv_block_3d(u6, 64)\n",
    "    \n",
    "    u7 = layers.Conv3DTranspose(32, (2,2,2), strides=(2,2,2), padding='same')(c6)\n",
    "    u7 = layers.concatenate([u7, c1])\n",
    "    c7 = conv_block_3d(u7, 32)\n",
    "    \n",
    "    outputs = layers.Conv3D(1, (1, 1, 1), activation='sigmoid')(c7)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_3d_unet()\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually inspect the Ground Truth images and masks\n",
    "def plot_images(images, masks, num_images=5):\n",
    "    for i in range(num_images):\n",
    "        idx = np.random.randint(0, len(images))\n",
    "        img = images[idx]\n",
    "        mask = masks[idx]\n",
    "        mid_slice = img.shape[0] // 2  # Select the middle slice\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        ax[0].imshow(img[mid_slice], cmap='gray')\n",
    "        ax[0].axis('off')\n",
    "        ax[0].set_title('Image (Middle Slice)')\n",
    "        ax[1].imshow(mask[mid_slice], cmap='gray')\n",
    "        ax[1].axis('off')\n",
    "        ax[1].set_title('Mask (Middle Slice)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_images(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate steps per epoch\n",
    "steps_per_epoch = len(X_train) // BATCH_SIZE\n",
    "validation_steps = len(X_val) // BATCH_SIZE\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"prostate_segmentation_best.keras\", \n",
    "        save_best_only=True, \n",
    "        monitor='val_loss',\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=10, \n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=3,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient_np(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Dice Similarity Coefficient.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: Ground truth mask (3D numpy array).\n",
    "    - y_pred: Predicted mask (3D numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - Dice coefficient.\n",
    "    \"\"\"\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (np.sum(y_true_f) + np.sum(y_pred_f) + 1e-8)\n",
    "\n",
    "def hausdorff_distance_np(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Hausdorff Distance between two binary masks.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: Ground truth mask (3D numpy array).\n",
    "    - y_pred: Predicted mask (3D numpy array).\n",
    "    \n",
    "    Returns:\n",
    "    - Hausdorff distance.\n",
    "    \"\"\"\n",
    "    y_true_pts = np.argwhere(y_true)\n",
    "    y_pred_pts = np.argwhere(y_pred)\n",
    "    \n",
    "    if len(y_true_pts) == 0 or len(y_pred_pts) == 0:\n",
    "        return np.inf\n",
    "    \n",
    "    forward_hd = directed_hausdorff(y_true_pts, y_pred_pts)[0]\n",
    "    backward_hd = directed_hausdorff(y_pred_pts, y_true_pts)[0]\n",
    "    \n",
    "    return max(forward_hd, backward_hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def visualize_prediction_3d(image_volume, ground_truth_volume, prediction_volume, idx):\n",
    "    \"\"\"\n",
    "    Display the middle slice of the 3D volume: original image, ground truth mask, and predicted mask.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_volume: 3D numpy array (depth, height, width).\n",
    "    - ground_truth_volume: 3D numpy array (depth, height, width).\n",
    "    - prediction_volume: 3D numpy array (depth, height, width).\n",
    "    - idx: Index of the sample.\n",
    "    \"\"\"\n",
    "    mid_slice = TARGET_DEPTH // 2\n",
    "    \n",
    "    plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image_volume[mid_slice], cmap='gray')\n",
    "    plt.title('Original Image (Middle Slice)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(ground_truth_volume[mid_slice], cmap='gray')\n",
    "    plt.title('Ground Truth Mask (Middle Slice)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(prediction_volume[mid_slice], cmap='gray')\n",
    "    plt.title('Predicted Mask (Middle Slice)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Sample {idx} - Middle Slice\")\n",
    "    plt.show()\n",
    "\n",
    "# Load the entire model (ensure the filename matches how you saved it)\n",
    "model = load_model(\"prostate_segmentation_best.keras\")\n",
    "\n",
    "# Predict on the validation set with reduced batch size to prevent OOM\n",
    "val_predictions = model.predict(X_val, batch_size=2)\n",
    "\n",
    "# Check prediction statistics\n",
    "print(\"Prediction stats:\")\n",
    "print(\"Min:\", np.min(val_predictions))\n",
    "print(\"Max:\", np.max(val_predictions))\n",
    "print(\"Mean:\", np.mean(val_predictions))\n",
    "print(\"Std:\", np.std(val_predictions))\n",
    "\n",
    "# Binarize predictions with threshold=0.5\n",
    "val_predictions_bin = (val_predictions > 0.5).astype(np.uint8)\n",
    "\n",
    "# Compute metrics\n",
    "dice_scores = []\n",
    "hausdorff_scores = []\n",
    "\n",
    "for i in range(len(y_val)):\n",
    "    dice = dice_coefficient_np(y_val[i], val_predictions_bin[i, :, :, :, 0])\n",
    "    hd = hausdorff_distance_np(y_val[i], val_predictions_bin[i, :, :, :, 0])\n",
    "    dice_scores.append(dice)\n",
    "    hausdorff_scores.append(hd)\n",
    "\n",
    "print(f\"Mean Dice Coefficient on Validation Set: {np.mean(dice_scores):.4f}\")\n",
    "print(f\"Mean Hausdorff Distance on Validation Set: {np.mean(hausdorff_scores):.4f} mm\")\n",
    "\n",
    "# Visualize the first validation sample\n",
    "visualize_prediction_3d(\n",
    "    X_val[0],\n",
    "    y_val[0],\n",
    "    val_predictions_bin[0, :, :, :, 0],\n",
    "    idx=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any positive labels in the first validation mask\n",
    "print(\"Sum of ground truth mask:\", np.sum(y_val[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"prostate_segmentation.keras\")\n",
    "print(\"Model saved as prostate_segmentation.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss and accuracy values\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss', color='orange')\n",
    "plt.title('Model Loss Over Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', color='green')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy', color='red')\n",
    "plt.title('Model Accuracy Over Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
