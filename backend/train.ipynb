{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "import pydicom\n",
    "from skimage import exposure\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "import logging\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BASE_SEGMENTATION_DIR = \"datasets\\segmentation\\PROSTATEx\"      # Directory containing segmentation masks\n",
    "BASE_IMAGES_DIR = \"datasets\\segmentation2\\PROSTATEx\"          # Directory containing image slices\n",
    "\n",
    "SEGMENTATION_FILENAME = \"1-1.dcm\"                                     # Segmentation mask filename per patient\n",
    "IMAGE_FILENAME_PATTERN = r\".*\\.dcm$\"                                  # Pattern to match image slices\n",
    "\n",
    "IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH = 256, 256, 19                       # Adjust IMG_DEPTH based on number of slices per patient\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_image(file_path):\n",
    "    \"\"\"\n",
    "    Load a DICOM file and return the image array.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dicom = pydicom.dcmread(file_path)\n",
    "        image = dicom.pixel_array.astype(np.float32)\n",
    "        # Rescale if necessary based on DICOM metadata\n",
    "        if 'RescaleSlope' in dicom and 'RescaleIntercept' in dicom:\n",
    "            slope = dicom.RescaleSlope\n",
    "            intercept = dicom.RescaleIntercept\n",
    "            image = image * slope + intercept\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading DICOM file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def denoise_image(image):\n",
    "    \"\"\"\n",
    "    Apply Non-Local Means denoising to the image.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: 2D numpy array\n",
    "    \n",
    "    Returns:\n",
    "    - denoised image\n",
    "    \"\"\"\n",
    "    # Estimate the noise standard deviation from the noisy image\n",
    "    sigma_est = np.mean(estimate_sigma(image))\n",
    "    denoised = denoise_nl_means(image, h=1.15 * sigma_est, fast_mode=True,\n",
    "                                patch_size=5, patch_distance=3)\n",
    "    return denoised\n",
    "\n",
    "def normalize_image(image, method='z-score'):\n",
    "    \"\"\"\n",
    "    Normalize the image using the specified method.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: 2D numpy array\n",
    "    - method: 'z-score' or 'minmax'\n",
    "    \n",
    "    Returns:\n",
    "    - normalized image\n",
    "    \"\"\"\n",
    "    if method == 'z-score':\n",
    "        mean = np.mean(image)\n",
    "        std = np.std(image)\n",
    "        normalized = (image - mean) / (std + 1e-8)\n",
    "    elif method == 'minmax':\n",
    "        min_val = np.min(image)\n",
    "        max_val = np.max(image)\n",
    "        normalized = (image - min_val) / (max_val - min_val + 1e-8)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown normalization method\")\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip_3d(volume, mask):\n",
    "    \"\"\"\n",
    "    Randomly flip the volume and mask along the horizontal and/or vertical axes.\n",
    "    \"\"\"\n",
    "    # Flip along the horizontal axis\n",
    "    if np.random.rand() < 0.5:\n",
    "        volume = np.flip(volume, axis=2)  # Assuming axis=2 is the width\n",
    "        mask = np.flip(mask, axis=2)\n",
    "    \n",
    "    # Flip along the vertical axis\n",
    "    if np.random.rand() < 0.5:\n",
    "        volume = np.flip(volume, axis=1)  # Assuming axis=1 is the height\n",
    "        mask = np.flip(mask, axis=1)\n",
    "    \n",
    "    return volume, mask\n",
    "\n",
    "def random_rotate_3d(volume, mask):\n",
    "    \"\"\"\n",
    "    Randomly rotate the volume and mask by 90 degrees around the depth axis.\n",
    "    \"\"\"\n",
    "    k = np.random.choice([0, 1, 2, 3])\n",
    "    volume = np.rot90(volume, k, axes=(1, 2))\n",
    "    mask = np.rot90(mask, k, axes=(1, 2))\n",
    "    return volume, mask\n",
    "\n",
    "def random_scale_3d(volume, mask, scale_range=(0.9, 1.1)):\n",
    "    \"\"\"\n",
    "    Randomly scale the volume and mask.\n",
    "    Note: Scaling in 3D is more complex; for simplicity, we'll scale each slice individually.\n",
    "    \"\"\"\n",
    "    scaled_volume = []\n",
    "    scaled_mask = []\n",
    "    for slice_img, slice_mask in zip(volume, mask):\n",
    "        scale = np.random.uniform(*scale_range)\n",
    "        height, width = slice_img.shape\n",
    "        new_h, new_w = int(height * scale), int(width * scale)\n",
    "        slice_img = cv2.resize(slice_img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "        slice_mask = cv2.resize(slice_mask, (new_w, new_h), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Crop or pad to maintain original size\n",
    "        if scale < 1.0:\n",
    "            pad_h = (height - new_h) // 2\n",
    "            pad_w = (width - new_w) // 2\n",
    "            slice_img = np.pad(slice_img, ((pad_h, height - new_h - pad_h), \n",
    "                                           (pad_w, width - new_w - pad_w)), mode='constant')\n",
    "            slice_mask = np.pad(slice_mask, ((pad_h, height - new_h - pad_h), \n",
    "                                           (pad_w, width - new_w - pad_w)), mode='constant')\n",
    "        else:\n",
    "            start_h = (new_h - height) // 2\n",
    "            start_w = (new_w - width) // 2\n",
    "            slice_img = slice_img[start_h:start_h + height, start_w:start_w + width]\n",
    "            slice_mask = slice_mask[start_h:start_h + height, start_w:start_w + width]\n",
    "        \n",
    "        scaled_volume.append(slice_img)\n",
    "        scaled_mask.append(slice_mask)\n",
    "    \n",
    "    scaled_volume = np.array(scaled_volume)\n",
    "    scaled_mask = np.array(scaled_mask)\n",
    "    \n",
    "    return scaled_volume, scaled_mask\n",
    "\n",
    "def augment_data_3d(volume, mask):\n",
    "    \"\"\"\n",
    "    Apply a series of random 3D augmentations to the volume and mask.\n",
    "    \"\"\"\n",
    "    volume, mask = random_flip_3d(volume, mask)\n",
    "    volume, mask = random_rotate_3d(volume, mask)\n",
    "    volume, mask = random_scale_3d(volume, mask)\n",
    "    return volume, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(segmentation_dir, images_dir, segmentation_filename, img_height, img_width, img_depth):\n",
    "    \"\"\"\n",
    "    Load images and masks from separate directories, preprocess them, and return as numpy arrays.\n",
    "    \n",
    "    Parameters:\n",
    "    - segmentation_dir: Directory containing segmentation masks\n",
    "    - images_dir: Directory containing image slices\n",
    "    - segmentation_filename: Filename of the segmentation mask per patient\n",
    "    - img_height: Desired image height after resizing\n",
    "    - img_width: Desired image width after resizing\n",
    "    - img_depth: Number of slices per patient\n",
    "    \n",
    "    Returns:\n",
    "    - images: Numpy array of preprocessed image volumes\n",
    "    - masks: Numpy array of corresponding segmentation masks\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    # List of patients based on segmentation directory\n",
    "    patients = os.listdir(segmentation_dir)\n",
    "    \n",
    "    for patient in patients:\n",
    "        patient_seg_dir = os.path.join(segmentation_dir, patient)\n",
    "        #print(patient_seg_dir)\n",
    "        if not os.path.isdir(patient_seg_dir):\n",
    "            print(f\"Skipping {patient}\")\n",
    "            continue  # Skip if not a directory\n",
    "        \n",
    "        # Path to segmentation mask\n",
    "        mask_path = os.path.join(patient_seg_dir, segmentation_filename)\n",
    "        # Sanitize the path cause the file name has a number in it\n",
    "        mask_path = mask_path.replace(\"\\\\\", \"/\")\n",
    "        #print(mask_path)\n",
    "        if not os.path.exists(mask_path):\n",
    "            #print(f\"Segmentation mask not found for patient: {patient}\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Segmentation mask found for patient: {patient}\")\n",
    "\n",
    "        # Load segmentation mask\n",
    "        mask_volume = load_dicom_image(mask_path)\n",
    "        if mask_volume is None:\n",
    "            #print(f\"Failed to load mask for patient: {patient}\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Mask loaded for patient: {patient}\")\n",
    "        \n",
    "        # Assuming mask_volume is a 3D array with shape (depth, height, width)\n",
    "        # If it's stored as multi-frame DICOM, ensure it's loaded correctly\n",
    "        # Here, we assume it's loaded as a 3D numpy array\n",
    "        if len(mask_volume.shape) == 2:\n",
    "            # Single slice mask; expand to 3D\n",
    "            mask_volume = np.expand_dims(mask_volume, axis=0)\n",
    "        \n",
    "        # Load image slices\n",
    "        patient_img_dir = os.path.join(images_dir, patient)\n",
    "\n",
    "        # Sanitize the path cause the file name has a number in it\n",
    "        patient_img_dir = patient_img_dir.replace(\"\\\\\", \"/\")\n",
    "        if not os.path.exists(patient_img_dir):\n",
    "            #print(f\"Image directory not found for patient: {patient}\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Image directory found for patient: {patient}\")\n",
    "        \n",
    "        # List all DICOM files in image directory\n",
    "        img_files = sorted([f for f in os.listdir(patient_img_dir) if re.match(IMAGE_FILENAME_PATTERN, f)])\n",
    "\n",
    "        # Sanitize the path cause the file name has a number in it\n",
    "        img_files = [f.replace(\"\\\\\", \"/\") for f in img_files]\n",
    "\n",
    "        if len(img_files) == 0:\n",
    "            #print(f\"No image slices found for patient: {patient}\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Image slices found for patient: {patient}\")\n",
    "        \n",
    "        # Load each slice\n",
    "        img_slices = []\n",
    "        for img_file in img_files:\n",
    "            img_path = os.path.join(patient_img_dir, img_file)\n",
    "            img_path = img_path.replace(\"\\\\\", \"/\")\n",
    "            img_slice = load_dicom_image(img_path)\n",
    "            if img_slice is None:\n",
    "                print(f\"Failed to load image slice: {img_path}\")\n",
    "                break\n",
    "            img_slices.append(img_slice)\n",
    "        \n",
    "        if len(img_slices) != img_depth:\n",
    "            print(f\"Unexpected number of slices for patient: {patient}. Expected {img_depth}, got {len(img_slices)}.\")\n",
    "            continue\n",
    "        \n",
    "        # Stack slices to form a 3D volume\n",
    "        img_volume = np.stack(img_slices, axis=0)  # Shape: (depth, height, width)\n",
    "        \n",
    "        # Preprocessing\n",
    "        img_volume = denoise_image(img_volume)\n",
    "        img_volume = normalize_image(img_volume, method='z-score')\n",
    "        \n",
    "        # Resize each slice\n",
    "        img_volume_resized = []\n",
    "        mask_volume_resized = []\n",
    "        for slice_img, slice_mask in zip(img_volume, mask_volume):\n",
    "            slice_img = cv2.resize(slice_img, (img_width, img_height), interpolation=cv2.INTER_LINEAR)\n",
    "            slice_mask = cv2.resize(slice_mask, (img_width, img_height), interpolation=cv2.INTER_NEAREST)\n",
    "            img_volume_resized.append(slice_img)\n",
    "            mask_volume_resized.append(slice_mask)\n",
    "        \n",
    "        img_volume_resized = np.array(img_volume_resized)\n",
    "        mask_volume_resized = np.array(mask_volume_resized)\n",
    "        \n",
    "        # Ensure masks are binary\n",
    "        mask_volume_resized = (mask_volume_resized > 0.5).astype(np.uint8)\n",
    "        \n",
    "        images.append(img_volume_resized)\n",
    "        masks.append(mask_volume_resized)\n",
    "\n",
    "        print(images)\n",
    "        print(masks)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    masks = np.array(masks)\n",
    "    \n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping LICENSE\n",
      "Segmentation mask found for patient: ProstateX-0004\n",
      "Mask loaded for patient: ProstateX-0004\n",
      "Image directory found for patient: ProstateX-0004\n",
      "Image slices found for patient: ProstateX-0004\n",
      "[array([[[-1.405619  , -1.4061869 , -1.4071844 , ..., -0.69648004,\n",
      "         -0.7282918 , -1.043816  ],\n",
      "        [-1.3961741 , -1.3966874 , -1.4084216 , ...,  0.7658621 ,\n",
      "          0.81251776,  0.149917  ],\n",
      "        [-1.4035134 , -0.7072568 ,  0.15798044, ..., -0.606623  ,\n",
      "         -0.482183  , -0.4548376 ],\n",
      "        ...,\n",
      "        [-1.4083972 , -1.4083357 , -1.4082916 , ..., -1.4035094 ,\n",
      "         -1.4060359 , -1.4072194 ],\n",
      "        [-1.4084176 , -1.408393  , -1.4083695 , ..., -1.4063904 ,\n",
      "         -1.4071817 , -1.4075536 ],\n",
      "        [-1.4084206 , -1.4084145 , -1.4083848 , ..., -1.4075558 ,\n",
      "         -1.4079317 , -1.4078405 ]],\n",
      "\n",
      "       [[-1.4059147 , -1.4063776 , -1.4073238 , ..., -0.60558796,\n",
      "         -0.69428533, -0.97405005],\n",
      "        [-1.4078151 , -1.4019612 , -1.4084216 , ...,  1.7776711 ,\n",
      "          1.5154355 ,  0.60146713],\n",
      "        [-1.4042146 , -1.3894901 , -0.5856048 , ...,  0.35928416,\n",
      "          0.38656008,  0.09943314],\n",
      "        ...,\n",
      "        [-1.4083972 , -1.4083357 , -1.4082949 , ..., -1.405014  ,\n",
      "         -1.4059056 , -1.4071994 ],\n",
      "        [-1.4084176 , -1.408393  , -1.4083695 , ..., -1.4062692 ,\n",
      "         -1.4071438 , -1.4075646 ],\n",
      "        [-1.4084206 , -1.4084145 , -1.4083848 , ..., -1.4075648 ,\n",
      "         -1.4079363 , -1.4078424 ]],\n",
      "\n",
      "       [[-1.4053807 , -1.4053595 , -1.4066334 , ..., -0.96037734,\n",
      "         -0.9417965 , -1.0827305 ],\n",
      "        [-1.4062436 , -1.4076779 , -1.407974  , ...,  0.82128227,\n",
      "          0.611634  , -0.01520727],\n",
      "        [-1.4036474 , -1.3860776 , -0.5228505 , ...,  1.3895648 ,\n",
      "          1.0467067 , -0.15228495],\n",
      "        ...,\n",
      "        [-1.4083972 , -1.4083357 , -1.4082832 , ..., -1.4034443 ,\n",
      "         -1.4055374 , -1.4071603 ],\n",
      "        [-1.4084176 , -1.408393  , -1.4083695 , ..., -1.4060795 ,\n",
      "         -1.4070415 , -1.4075596 ],\n",
      "        [-1.4084206 , -1.4084145 , -1.4083848 , ..., -1.4075727 ,\n",
      "         -1.40794   , -1.4078469 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-1.4043272 , -1.4055074 , -1.4060577 , ..., -1.4052175 ,\n",
      "         -1.3980124 , -1.4021895 ],\n",
      "        [-1.4049869 , -1.4055344 , -1.4062531 , ..., -1.3764455 ,\n",
      "         -1.4007533 , -1.402386  ],\n",
      "        [-1.4042891 , -1.4044193 , -1.4063032 , ...,  2.5011938 ,\n",
      "         -1.389609  , -1.405987  ],\n",
      "        ...,\n",
      "        [-1.4084216 , -1.4081657 , -1.4070212 , ..., -1.3756657 ,\n",
      "         -1.3903862 , -1.3960048 ],\n",
      "        [-1.4084216 , -1.4084216 , -1.4084188 , ..., -1.3923974 ,\n",
      "         -1.3981313 , -1.3997027 ],\n",
      "        [-1.4084216 , -1.4084216 , -1.4084216 , ..., -1.3990412 ,\n",
      "         -1.4018093 , -1.4022164 ]],\n",
      "\n",
      "       [[-1.404154  , -1.4053717 , -1.4059591 , ..., -1.4052178 ,\n",
      "         -1.3976054 , -1.4021916 ],\n",
      "        [-1.4048586 , -1.4054208 , -1.4061726 , ..., -1.3707461 ,\n",
      "         -1.4003427 , -1.4023864 ],\n",
      "        [-1.4041164 , -1.4042474 , -1.4062164 , ...,  2.9732196 ,\n",
      "         -1.3946329 , -1.4059877 ],\n",
      "        ...,\n",
      "        [-1.4084216 , -1.4081657 , -1.4069166 , ..., -1.3758422 ,\n",
      "         -1.3880169 , -1.3926502 ],\n",
      "        [-1.4084216 , -1.4084216 , -1.4084188 , ..., -1.3906109 ,\n",
      "         -1.3961837 , -1.3973393 ],\n",
      "        [-1.4084216 , -1.4084216 , -1.4084216 , ..., -1.3963721 ,\n",
      "         -1.3996253 , -1.3999674 ]],\n",
      "\n",
      "       [[-1.4042692 , -1.4054437 , -1.4060271 , ..., -1.4052178 ,\n",
      "         -1.3980823 , -1.4021916 ],\n",
      "        [-1.4049032 , -1.4054384 , -1.4062027 , ..., -1.3646733 ,\n",
      "         -1.4008197 , -1.4023864 ],\n",
      "        [-1.4041122 , -1.404213  , -1.4062164 , ...,  2.6749907 ,\n",
      "         -1.3893788 , -1.4059876 ],\n",
      "        ...,\n",
      "        [-1.4084216 , -1.4081767 , -1.4072218 , ..., -1.3690656 ,\n",
      "         -1.3846519 , -1.3910865 ],\n",
      "        [-1.4084216 , -1.4084216 , -1.4084216 , ..., -1.3874481 ,\n",
      "         -1.3944035 , -1.3963311 ],\n",
      "        [-1.4084216 , -1.4084216 , -1.4084216 , ..., -1.3943328 ,\n",
      "         -1.3983605 , -1.3990895 ]]], dtype=float32)]\n",
      "[array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)]\n",
      "Loaded 1 patients.\n",
      "Image shape: (1, 19, 256, 256)\n",
      "Mask shape: (1, 19, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "images, masks = load_dataset(\n",
    "    segmentation_dir=BASE_SEGMENTATION_DIR,\n",
    "    images_dir=BASE_IMAGES_DIR,\n",
    "    segmentation_filename=SEGMENTATION_FILENAME,\n",
    "    img_height=IMG_HEIGHT,\n",
    "    img_width=IMG_WIDTH,\n",
    "    img_depth=IMG_DEPTH\n",
    ")\n",
    "\n",
    "print(f\"Loaded {images.shape[0]} patients.\")\n",
    "print(f\"Image shape: {images.shape}\")  # Expected: (num_patients, depth, height, width)\n",
    "print(f\"Mask shape: {masks.shape}\")    # Expected: (num_patients, depth, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    images, masks, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape=(256, 256, 1)):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "    \n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "    \n",
    "    # Decoder\n",
    "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = layers.concatenate([u6, c4])\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "    \n",
    "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "    \n",
    "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "    \n",
    "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = layers.concatenate([u9, c1])\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "    \n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    \n",
    "    model = keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_unet()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate steps per epoch\n",
    "steps_per_epoch = len(X_train) // BATCH_SIZE\n",
    "validation_steps = len(X_val) // BATCH_SIZE\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"prostate_segmentation_best.keras\", save_best_only=True, monitor='val_loss'),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Dice Similarity Coefficient.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: Ground truth mask\n",
    "    - y_pred: Predicted mask\n",
    "    \n",
    "    Returns:\n",
    "    - Dice coefficient\n",
    "    \"\"\"\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (np.sum(y_true_f) + np.sum(y_pred_f) + 1e-8)\n",
    "\n",
    "def hausdorff_distance(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Hausdorff Distance between two binary masks.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: Ground truth mask\n",
    "    - y_pred: Predicted mask\n",
    "    \n",
    "    Returns:\n",
    "    - Hausdorff distance\n",
    "    \"\"\"\n",
    "    y_true_pts = np.argwhere(y_true)\n",
    "    y_pred_pts = np.argwhere(y_pred)\n",
    "    \n",
    "    if len(y_true_pts) == 0 or len(y_pred_pts) == 0:\n",
    "        return np.inf\n",
    "    \n",
    "    forward_hd = directed_hausdorff(y_true_pts, y_pred_pts)[0]\n",
    "    backward_hd = directed_hausdorff(y_pred_pts, y_true_pts)[0]\n",
    "    \n",
    "    return max(forward_hd, backward_hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model.load_weights(\"prostate_segmentation_best.h5\")\n",
    "\n",
    "# Predict on the validation set\n",
    "val_predictions = model.predict(X_val[:])\n",
    "\n",
    "# Binarize predictions\n",
    "val_predictions_bin = (val_predictions > 0.5).astype(np.uint8)\n",
    "\n",
    "# Compute metrics\n",
    "dice_scores = []\n",
    "hausdorff_scores = []\n",
    "\n",
    "for i in range(len(y_val)):\n",
    "    dice = dice_coefficient(y_val[i], val_predictions_bin[i, :, :, 0])\n",
    "    hd = hausdorff_distance(y_val[i], val_predictions_bin[i, :, :, 0])\n",
    "    dice_scores.append(dice)\n",
    "    hausdorff_scores.append(hd)\n",
    "\n",
    "print(f\"Mean Dice Coefficient on Validation Set: {np.mean(dice_scores):.4f}\")\n",
    "print(f\"Mean Hausdorff Distance on Validation Set: {np.mean(hausdorff_scores):.4f} mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"prostate_segmentation.keras\")\n",
    "print(\"Model saved as prostate_segmentation.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
