{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "\n",
    "# Model building\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth set for GPUs.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Memory growth set for GPUs.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPUs detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the CSV file\n",
    "data_path = \"dataset/fer2013/fer2013/fer2013.csv\"  # Update this path to your CSV file\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Inspect the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data shape: (35887, 48, 48, 1)\n",
      "Label data shape: (35887,)\n"
     ]
    }
   ],
   "source": [
    "# Convert pixel values from string to numpy array\n",
    "def preprocess_images(df):\n",
    "    images = []\n",
    "    for pixel_sequence in df[\"pixels\"]:\n",
    "        img_array = np.array(pixel_sequence.split(), dtype=\"float32\")\n",
    "        img_array = img_array.reshape(48, 48, 1)  # Reshape to 48x48 and single channel\n",
    "        img_array = img_array / 255.0  # Normalize pixel values to [0, 1]\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "# Preprocess images and extract labels\n",
    "X = preprocess_images(df)\n",
    "y = df[\"emotion\"].values  # Emotion labels\n",
    "\n",
    "# Check the shape of images and labels\n",
    "print(\"Image data shape:\", X.shape)  # Should be (num_samples, 48, 48, 1)\n",
    "print(\"Label data shape:\", y.shape)  # Should be (num_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (25120, 48, 48, 1)\n",
      "Validation set shape: (5383, 48, 48, 1)\n",
      "Test set shape: (5384, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 512)       590336    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1179904   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,474,631\n",
      "Trainable params: 4,472,711\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), activation=\"relu\", input_shape=(48, 48, 1), padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Conv2D(128, (5, 5), activation=\"relu\", padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Dense(512, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Dense(7, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.005),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "785/785 [==============================] - 21s 18ms/step - loss: 1.9944 - accuracy: 0.2299 - val_loss: 1.8428 - val_accuracy: 0.2357\n",
      "Epoch 2/30\n",
      "785/785 [==============================] - 14s 17ms/step - loss: 1.6189 - accuracy: 0.3768 - val_loss: 1.7239 - val_accuracy: 0.3572\n",
      "Epoch 3/30\n",
      "785/785 [==============================] - 13s 17ms/step - loss: 1.4343 - accuracy: 0.4438 - val_loss: 1.4625 - val_accuracy: 0.4561\n",
      "Epoch 4/30\n",
      "785/785 [==============================] - 13s 16ms/step - loss: 1.2911 - accuracy: 0.5031 - val_loss: 1.2777 - val_accuracy: 0.5166\n",
      "Epoch 5/30\n",
      "785/785 [==============================] - 13s 16ms/step - loss: 1.2037 - accuracy: 0.5432 - val_loss: 1.2963 - val_accuracy: 0.5008\n",
      "Epoch 6/30\n",
      "785/785 [==============================] - 13s 17ms/step - loss: 1.3430 - accuracy: 0.4828 - val_loss: 1.2968 - val_accuracy: 0.5094\n",
      "Epoch 7/30\n",
      "785/785 [==============================] - 13s 16ms/step - loss: 1.1803 - accuracy: 0.5537 - val_loss: 1.1728 - val_accuracy: 0.5538\n",
      "Epoch 8/30\n",
      "785/785 [==============================] - 13s 17ms/step - loss: 1.0657 - accuracy: 0.5996 - val_loss: 1.1403 - val_accuracy: 0.5768\n",
      "Epoch 9/30\n",
      "785/785 [==============================] - 13s 16ms/step - loss: 0.9798 - accuracy: 0.6377 - val_loss: 1.1757 - val_accuracy: 0.5651\n",
      "Epoch 10/30\n",
      "785/785 [==============================] - 13s 17ms/step - loss: 0.8826 - accuracy: 0.6755 - val_loss: 1.5522 - val_accuracy: 0.4490\n",
      "Epoch 11/30\n",
      "785/785 [==============================] - 13s 17ms/step - loss: 0.7833 - accuracy: 0.7145 - val_loss: 1.2039 - val_accuracy: 0.5755\n",
      "Epoch 12/30\n",
      "785/785 [==============================] - 13s 17ms/step - loss: 0.6806 - accuracy: 0.7509 - val_loss: 1.3312 - val_accuracy: 0.5720\n",
      "Epoch 13/30\n",
      "785/785 [==============================] - 13s 17ms/step - loss: 0.5814 - accuracy: 0.7928 - val_loss: 1.4250 - val_accuracy: 0.5744\n"
     ]
    }
   ],
   "source": [
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(\"model/emotions.keras\", save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 1s 6ms/step - loss: 1.1403 - accuracy: 0.5768\n",
      "Validation Loss: 1.1403216123580933\n",
      "Validation Accuracy: 0.5768159031867981\n",
      "169/169 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.42      0.47       743\n",
      "           1       0.65      0.21      0.31        82\n",
      "           2       0.43      0.27      0.33       768\n",
      "           3       0.79      0.81      0.80      1348\n",
      "           4       0.46      0.49      0.48       911\n",
      "           5       0.76      0.64      0.70       601\n",
      "           6       0.44      0.69      0.54       930\n",
      "\n",
      "    accuracy                           0.58      5383\n",
      "   macro avg       0.58      0.50      0.52      5383\n",
      "weighted avg       0.58      0.58      0.57      5383\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Generate classification report\n",
    "y_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/mystery.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
